{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b72a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DASHSCOPE_API_KEY = os.getenv('DASHSCOPE_API_KEY')\n",
    "if not DASHSCOPE_API_KEY:\n",
    "    raise ValueError(\"请设置环境变量 DASHSCOPE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8730b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_page_numbers(pdf) -> Tuple[str, List[Tuple[str, int]]]:\n",
    "    \"\"\"\n",
    "    从PDF中提取文本并记录每个字符对应的页码\n",
    "    \n",
    "    参数:\n",
    "        pdf: PDF文件对象\n",
    "    \n",
    "    返回:\n",
    "        text: 提取的文本内容\n",
    "        char_page_mapping: 每个字符对应的页码列表\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    char_page_mapping = []\n",
    "\n",
    "    for page_number, page in enumerate(pdf.pages, start=1):\n",
    "        extracted_text = page.extract_text()\n",
    "        if extracted_text:\n",
    "            text += extracted_text\n",
    "            # 为当前页面的每个字符记录页码\n",
    "            char_page_mapping.extend([page_number] * len(extracted_text))\n",
    "        else:\n",
    "            print(f\"No text found on page {page_number}.\")\n",
    "\n",
    "    return text, char_page_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6dfb0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_with_splitter(text: str, char_page_mapping: List[int], save_path: str = None) -> FAISS:\n",
    "    \"\"\"\n",
    "    处理文本并创建向量存储\n",
    "    \n",
    "    参数:\n",
    "        text: 提取的文本内容\n",
    "        char_page_mapping: 每个字符对应的页码列表\n",
    "        save_path: 可选，保存向量数据库的路径\n",
    "    \n",
    "    返回:\n",
    "        knowledgeBase: 基于FAISS的向量存储对象\n",
    "    \"\"\"\n",
    "    # 创建文本分割器，用于将长文本分割成小块\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "    )\n",
    "\n",
    "    # 分割文本\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    print(f\"文本被分割成 {len(chunks)} 个块。\")\n",
    "        \n",
    "    # 创建嵌入模型\n",
    "    embeddings = DashScopeEmbeddings(\n",
    "        model=\"text-embedding-v1\",\n",
    "        dashscope_api_key=DASHSCOPE_API_KEY,\n",
    "    )\n",
    "    \n",
    "    # 从文本块创建知识库\n",
    "    knowledgeBase = FAISS.from_texts(chunks, embeddings)\n",
    "    print(\"已从文本块创建知识库。\")\n",
    "    \n",
    "    # 为每个文本块找到对应的页码信息\n",
    "    page_info = {}\n",
    "    current_pos = 0\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        chunk_start = current_pos\n",
    "        chunk_end = current_pos + len(chunk)\n",
    "        \n",
    "        # 找到这个文本块中字符对应的页码\n",
    "        chunk_pages = char_page_mapping[chunk_start:chunk_end]\n",
    "        \n",
    "        # 取页码的众数（出现最多的页码）作为该块的页码\n",
    "        if chunk_pages:\n",
    "            # 统计每个页码出现的次数\n",
    "            page_counts = {}\n",
    "            for page in chunk_pages:\n",
    "                page_counts[page] = page_counts.get(page, 0) + 1\n",
    "            \n",
    "            # 找到出现次数最多的页码\n",
    "            most_common_page = max(page_counts, key=page_counts.get)\n",
    "            page_info[chunk] = most_common_page\n",
    "        else:\n",
    "            page_info[chunk] = 1  # 默认页码\n",
    "        \n",
    "        current_pos = chunk_end\n",
    "    \n",
    "    knowledgeBase.page_info = page_info\n",
    "    print(f'页码映射完成，共 {len(page_info)} 个文本块')\n",
    "    \n",
    "    # 如果提供了保存路径，则保存向量数据库和页码信息\n",
    "    if save_path:\n",
    "        # 确保目录存在\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        # 保存FAISS向量数据库\n",
    "        knowledgeBase.save_local(save_path)\n",
    "        print(f\"向量数据库已保存到: {save_path}\")\n",
    "        \n",
    "        # 保存页码信息到同一目录\n",
    "        with open(os.path.join(save_path, \"page_info.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(page_info, f)\n",
    "        print(f\"页码信息已保存到: {os.path.join(save_path, 'page_info.pkl')}\")\n",
    "    \n",
    "    return knowledgeBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed958cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_numbers= <built-in method count of list object at 0x7f9aa726c040>\n"
     ]
    }
   ],
   "source": [
    "# 读取PDF文件\n",
    "pdf_reader = PdfReader('./浦发上海浦东发展银行西安分行个金客户经理考核办法.pdf')\n",
    "# # 提取文本和页码信息\n",
    "text, char_page_mapping = extract_text_with_page_numbers(pdf_reader)\n",
    "print('page_numbers=',char_page_mapping.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e16c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本被分割成 5 个块。\n",
      "已从文本块创建知识库。\n",
      "页码映射完成，共 5 个文本块\n",
      "向量数据库已保存到: ./vector_db\n",
      "页码信息已保存到: ./vector_db/page_info.pkl\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"./vector_db\"\n",
    "knowledgeBase = process_text_with_splitter(text, char_page_mapping, save_path=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e3c741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Tongyi\n",
    "llm = Tongyi(model_name=\"deepseek-v3\", dashscope_api_key=DASHSCOPE_API_KEY) # qwen-turbo\n",
    "\n",
    "# 设置查询问题\n",
    "#query = \"客户经理被投诉了，投诉一次扣多少分\"\n",
    "#query = \"客户经理每年评聘申报时间是怎样的？\"\n",
    "def query_pdf(query, knowledgeBase):\n",
    "    # 执行相似度搜索，找到与查询相关的文档\n",
    "    docs = knowledgeBase.similarity_search(query,k=10)\n",
    "\n",
    "    # 加载问答链\n",
    "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "    # 准备输入数据\n",
    "    input_data = {\"input_documents\": docs, \"question\": query}\n",
    "\n",
    "    # 执行问答链\n",
    "    response = chain.invoke(input=input_data)\n",
    "    print(response[\"output_text\"])\n",
    "    print(\"来源:\")\n",
    "\n",
    "    # 记录唯一的页码\n",
    "    unique_pages = set()\n",
    "\n",
    "    # 显示每个文档块的来源页码\n",
    "    for doc in docs:\n",
    "        #print('doc=',doc)\n",
    "        text_content = getattr(doc, \"page_content\", \"\")\n",
    "        source_page = knowledgeBase.page_info.get(\n",
    "            text_content.strip(), \"未知\"\n",
    "        )\n",
    "\n",
    "        if source_page not in unique_pages:\n",
    "            unique_pages.add(source_page)\n",
    "            print(f\"文本块页码: {source_page}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f0b782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18742/540925427.py:12: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
      "  chain = load_qa_chain(llm, chain_type=\"stuff\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据提供的信息，客户经理被投诉一次扣 **2分**。\n",
      "来源:\n",
      "文本块页码: 6\n",
      "文本块页码: 1\n",
      "文本块页码: 8\n",
      "文本块页码: 4\n"
     ]
    }
   ],
   "source": [
    "query = \"客户经理被投诉了，投诉一次扣多少分\"\n",
    "query_pdf(query, knowledgeBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a3580ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量数据库已从 ./vector_db 加载。\n",
      "页码信息已加载。\n",
      "根据提供的信息，客户经理每年评聘申报时间为**每年一月份**。这是由分行人力资源部和个人业务部在每年二月份组织统一资格考试的前提条件。\n",
      "来源:\n",
      "文本块页码: 8\n",
      "文本块页码: 6\n",
      "文本块页码: 1\n",
      "文本块页码: 4\n"
     ]
    }
   ],
   "source": [
    "def load_knowledge_base(load_path: str, embeddings = None) -> FAISS:\n",
    "    \"\"\"\n",
    "    从磁盘加载向量数据库和页码信息\n",
    "    \n",
    "    参数:\n",
    "        load_path: 向量数据库的保存路径\n",
    "        embeddings: 可选，嵌入模型。如果为None，将创建一个新的DashScopeEmbeddings实例\n",
    "    \n",
    "    返回:\n",
    "        knowledgeBase: 加载的FAISS向量数据库对象\n",
    "    \"\"\"\n",
    "    # 如果没有提供嵌入模型，则创建一个新的\n",
    "    if embeddings is None:\n",
    "        embeddings = DashScopeEmbeddings(\n",
    "            model=\"text-embedding-v1\",\n",
    "            dashscope_api_key=DASHSCOPE_API_KEY,\n",
    "        )\n",
    "    \n",
    "    # 加载FAISS向量数据库，添加allow_dangerous_deserialization=True参数以允许反序列化\n",
    "    knowledgeBase = FAISS.load_local(load_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(f\"向量数据库已从 {load_path} 加载。\")\n",
    "    \n",
    "    # 加载页码信息\n",
    "    page_info_path = os.path.join(load_path, \"page_info.pkl\")\n",
    "    if os.path.exists(page_info_path):\n",
    "        with open(page_info_path, \"rb\") as f:\n",
    "            page_info = pickle.load(f)\n",
    "        knowledgeBase.page_info = page_info\n",
    "        print(\"页码信息已加载。\")\n",
    "    else:\n",
    "        print(\"警告: 未找到页码信息文件。\")\n",
    "    \n",
    "    return knowledgeBase\n",
    "\n",
    "embeddings = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v1\",\n",
    "    dashscope_api_key=DASHSCOPE_API_KEY,\n",
    ")\n",
    "# 从磁盘加载向量数据库\n",
    "loaded_knowledgeBase = load_knowledge_base(\"./vector_db\", embeddings)\n",
    "query = \"客户经理每年评聘申报时间是怎样的？\"\n",
    "query_pdf(query, loaded_knowledgeBase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
